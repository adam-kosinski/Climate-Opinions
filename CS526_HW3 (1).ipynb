{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1_f5S_lsxnZ"
   },
   "source": [
    "The code below is modified from https://github.com/rasbt/mlxtend/blob/master/mlxtend/frequent_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6Xtd9T0sVBZ"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import warnings\n",
    "from distutils.version import LooseVersion as Version\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import __version__ as pandas_version\n",
    "\n",
    "warnings.simplefilter(\"always\", DeprecationWarning)\n",
    "\n",
    "\n",
    "def setup_fptree(df, min_support):\n",
    "    num_itemsets = len(df.index)  # number of itemsets in the database\n",
    "\n",
    "    is_sparse = False\n",
    "    if hasattr(df, \"sparse\"):\n",
    "        # DataFrame with SparseArray (pandas >= 0.24)\n",
    "        if df.size == 0:\n",
    "            itemsets = df.values\n",
    "        else:\n",
    "            itemsets = df.sparse.to_coo().tocsr()\n",
    "            is_sparse = True\n",
    "    else:\n",
    "        # dense DataFrame\n",
    "        itemsets = df.values\n",
    "\n",
    "    # support of each individual item\n",
    "    # if itemsets is sparse, np.sum returns an np.matrix of shape (1, N)\n",
    "    item_support = np.array(np.sum(itemsets, axis=0) / float(num_itemsets))\n",
    "    item_support = item_support.reshape(-1)\n",
    "\n",
    "    items = np.nonzero(item_support >= min_support)[0]\n",
    "\n",
    "    # Define ordering on items for inserting into FPTree\n",
    "    indices = item_support[items].argsort()\n",
    "    rank = {item: i for i, item in enumerate(items[indices])}\n",
    "\n",
    "    if is_sparse:\n",
    "        # Ensure that there are no zeros in sparse DataFrame\n",
    "        itemsets.eliminate_zeros()\n",
    "\n",
    "    # Building tree by inserting itemsets in sorted order\n",
    "    # Heuristic for reducing tree size is inserting in order\n",
    "    #   of most frequent to least frequent\n",
    "    tree = FPTree(rank)\n",
    "    for i in range(num_itemsets):\n",
    "        if is_sparse:\n",
    "            # itemsets has been converted to CSR format to speed-up the line\n",
    "            # below.  It has 3 attributes:\n",
    "            #  - itemsets.data contains non null values, shape(#nnz,)\n",
    "            #  - itemsets.indices contains the column number of non null\n",
    "            #    elements, shape(#nnz,)\n",
    "            #  - itemsets.indptr[i] contains the offset in itemset.indices of\n",
    "            #    the first non null element in row i, shape(1+#nrows,)\n",
    "            nonnull = itemsets.indices[itemsets.indptr[i] :\n",
    "                                       itemsets.indptr[i + 1]]\n",
    "        else:\n",
    "            nonnull = np.where(itemsets[i, :])[0]\n",
    "        itemset = [item for item in nonnull if item in rank]\n",
    "        itemset.sort(key=rank.get, reverse=True)\n",
    "        tree.insert_itemset(itemset)\n",
    "\n",
    "    return tree, rank\n",
    "\n",
    "\n",
    "def generate_itemsets(generator, num_itemsets, colname_map):\n",
    "    itemsets = []\n",
    "    supports = []\n",
    "    for sup, iset in generator:\n",
    "        itemsets.append(frozenset(iset))\n",
    "        supports.append(sup / num_itemsets)\n",
    "\n",
    "    res_df = pd.DataFrame({\"support\": supports, \"itemsets\": itemsets})\n",
    "\n",
    "    if colname_map is not None:\n",
    "        res_df[\"itemsets\"] = res_df[\"itemsets\"].apply(\n",
    "            lambda x: frozenset([colname_map[i] for i in x])\n",
    "        )\n",
    "\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def valid_input_check(df):\n",
    "    if f\"{type(df)}\" == \"<class 'pandas.core.frame.SparseDataFrame'>\":\n",
    "        msg = (\n",
    "            \"SparseDataFrame support has been deprecated in pandas 1.0,\"\n",
    "            \" and is no longer supported in mlxtend. \"\n",
    "            \" Please\"\n",
    "            \" see the pandas migration guide at\"\n",
    "            \" https://pandas.pydata.org/pandas-docs/\"\n",
    "            \"stable/user_guide/sparse.html#sparse-data-structures\"\n",
    "            \" for supporting sparse data in DataFrames.\"\n",
    "        )\n",
    "        raise TypeError(msg)\n",
    "\n",
    "    if df.size == 0:\n",
    "        return\n",
    "    if hasattr(df, \"sparse\"):\n",
    "        if not isinstance(df.columns[0], str) and df.columns[0] != 0:\n",
    "            raise ValueError(\n",
    "                \"Due to current limitations in Pandas, \"\n",
    "                \"if the sparse format has integer column names,\"\n",
    "                \"names, please make sure they either start \"\n",
    "                \"with `0` or cast them as string column names: \"\n",
    "                \"`df.columns = [str(i) for i in df.columns`].\"\n",
    "            )\n",
    "\n",
    "    # Fast path: if all columns are boolean, there is nothing to checks\n",
    "    all_bools = df.dtypes.apply(pd.api.types.is_bool_dtype).all()\n",
    "    if not all_bools:\n",
    "        warnings.warn(\n",
    "            \"DataFrames with non-bool types result in worse computational\"\n",
    "            \"performance and their support might be discontinued in the future.\"\n",
    "            \"Please use a DataFrame with bool type\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "        # Pandas is much slower than numpy, so use np.where on Numpy arrays\n",
    "        if hasattr(df, \"sparse\"):\n",
    "            if df.size == 0:\n",
    "                values = df.values\n",
    "            else:\n",
    "                values = df.sparse.to_coo().tocoo().data\n",
    "        else:\n",
    "            values = df.values\n",
    "        idxs = np.where((values != 1) & (values != 0))\n",
    "        if len(idxs[0]) > 0:\n",
    "            # idxs has 1 dimension with sparse data and 2 with dense data\n",
    "            val = values[tuple(loc[0] for loc in idxs)]\n",
    "            s = (\n",
    "                \"The allowed values for a DataFrame\"\n",
    "                \" are True, False, 0, 1. Found value %s\" % (val)\n",
    "            )\n",
    "            raise ValueError(s)\n",
    "\n",
    "\n",
    "class FPTree(object):\n",
    "    def __init__(self, rank=None):\n",
    "        self.root = FPNode(None)\n",
    "        self.nodes = collections.defaultdict(list)\n",
    "        self.cond_items = []\n",
    "        self.rank = rank\n",
    "\n",
    "    def conditional_tree(self, cond_item, minsup):\n",
    "        \"\"\"\n",
    "        Creates and returns the subtree of self conditioned on cond_item.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cond_item : int | str\n",
    "            Item that the tree (self) will be conditioned on.\n",
    "        minsup : int\n",
    "            Minimum support threshold.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cond_tree : FPtree\n",
    "        \"\"\"\n",
    "        # Find all path from root node to nodes for item\n",
    "        branches = []\n",
    "        count = collections.defaultdict(int)\n",
    "        for node in self.nodes[cond_item]:\n",
    "            branch = node.itempath_from_root()\n",
    "            branches.append(branch)\n",
    "            for item in branch:\n",
    "                count[item] += node.count\n",
    "\n",
    "        # Define new ordering or deep trees may have combinatorially explosion\n",
    "        items = [item for item in count if count[item] >= minsup]\n",
    "        items.sort(key=count.get)\n",
    "        rank = {item: i for i, item in enumerate(items)}\n",
    "\n",
    "        # Create conditional tree\n",
    "        cond_tree = FPTree(rank)\n",
    "        for idx, branch in enumerate(branches):\n",
    "            branch = sorted(\n",
    "                [i for i in branch if i in rank], key=rank.get, reverse=True\n",
    "            )\n",
    "            cond_tree.insert_itemset(branch, self.nodes[cond_item][idx].count)\n",
    "        cond_tree.cond_items = self.cond_items + [cond_item]\n",
    "\n",
    "        return cond_tree\n",
    "\n",
    "    def insert_itemset(self, itemset, count=1):\n",
    "        \"\"\"\n",
    "        Inserts a list of items into the tree.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        itemset : list\n",
    "            Items that will be inserted into the tree.\n",
    "        count : int\n",
    "            The number of occurrences of the itemset.\n",
    "        \"\"\"\n",
    "        self.root.count += count\n",
    "\n",
    "        if len(itemset) == 0:\n",
    "            return\n",
    "\n",
    "        # Follow existing path in tree as long as possible\n",
    "        index = 0\n",
    "        node = self.root\n",
    "        for item in itemset:\n",
    "            if item in node.children:\n",
    "                child = node.children[item]\n",
    "                child.count += count\n",
    "                node = child\n",
    "                index += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Insert any remaining items\n",
    "        for item in itemset[index:]:\n",
    "            child_node = FPNode(item, count, node)\n",
    "            self.nodes[item].append(child_node)\n",
    "            node = child_node\n",
    "\n",
    "    def is_path(self):\n",
    "        if len(self.root.children) > 1:\n",
    "            return False\n",
    "        for i in self.nodes:\n",
    "            if len(self.nodes[i]) > 1 or len(self.nodes[i][0].children) > 1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def print_status(self, count, colnames):\n",
    "        cond_items = [str(i) for i in self.cond_items]\n",
    "        if colnames:\n",
    "            cond_items = [str(colnames[i]) for i in self.cond_items]\n",
    "        cond_items = \", \".join(cond_items)\n",
    "        print(\n",
    "            \"\\r%d itemset(s) from tree conditioned on items (%s)\" % (count, cond_items),\n",
    "            end=\"\\n\",\n",
    "        )\n",
    "\n",
    "\n",
    "class FPNode(object):\n",
    "    def __init__(self, item, count=0, parent=None):\n",
    "        self.item = item\n",
    "        self.count = count\n",
    "        self.parent = parent\n",
    "        self.children = collections.defaultdict(FPNode)\n",
    "\n",
    "        if parent is not None:\n",
    "            parent.children[item] = self\n",
    "\n",
    "    def itempath_from_root(self):\n",
    "        \"\"\"Returns the top-down sequence of items from self to\n",
    "        (but not including) the root node.\"\"\"\n",
    "        path = []\n",
    "        if self.item is None:\n",
    "            return path\n",
    "\n",
    "        node = self.parent\n",
    "        while node.item is not None:\n",
    "            path.append(node.item)\n",
    "            node = node.parent\n",
    "\n",
    "        path.reverse()\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GcFjSiKvskMq",
    "outputId": "3ea9a448-cb3e-4535-a0c7-92fdcd9e4275"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# mlxtend Machine Learning Library Extensions\n",
    "# Author: Steve Harenberg <harenbergsd@gmail.com>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def fpgrowth(df, min_support=0.5, use_colnames=False, max_len=None, verbose=0):\n",
    "    \"\"\"Get frequent itemsets from a one-hot DataFrame\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "      pandas DataFrame the encoded format. Also supports\n",
    "      DataFrames with sparse data; for more info, please\n",
    "      see https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#sparse-data-structures.\n",
    "\n",
    "      Please note that the old pandas SparseDataFrame format\n",
    "      is no longer supported in mlxtend >= 0.17.2.\n",
    "\n",
    "      The allowed values are either 0/1 or True/False.\n",
    "      For example,\n",
    "\n",
    "    ```\n",
    "           Apple  Bananas   Beer  Chicken   Milk   Rice\n",
    "        0   True    False   True     True  False   True\n",
    "        1   True    False   True    False  False   True\n",
    "        2   True    False   True    False  False  False\n",
    "        3   True     True  False    False  False  False\n",
    "        4  False    False   True     True   True   True\n",
    "        5  False    False   True    False   True   True\n",
    "        6  False    False   True    False   True  False\n",
    "        7   True     True  False    False  False  False\n",
    "    ```\n",
    "\n",
    "    min_support : float (default: 0.5)\n",
    "      A float between 0 and 1 for minimum support of the itemsets returned.\n",
    "      The support is computed as the fraction\n",
    "      transactions_where_item(s)_occur / total_transactions.\n",
    "\n",
    "    use_colnames : bool (default: False)\n",
    "      If true, uses the DataFrames' column names in the returned DataFrame\n",
    "      instead of column indices.\n",
    "\n",
    "    max_len : int (default: None)\n",
    "      Maximum length of the itemsets generated. If `None` (default) all\n",
    "      possible itemsets lengths are evaluated.\n",
    "\n",
    "    verbose : int (default: 0)\n",
    "      Shows the stages of conditional tree generation.\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    pandas DataFrame with columns ['support', 'itemsets'] of all itemsets\n",
    "      that are >= `min_support` and < than `max_len`\n",
    "      (if `max_len` is not None).\n",
    "      Each itemset in the 'itemsets' column is of type `frozenset`,\n",
    "      which is a Python built-in type that behaves similarly to\n",
    "      sets except that it is immutable\n",
    "      (For more info, see\n",
    "      https://docs.python.org/3.6/library/stdtypes.html#frozenset).\n",
    "\n",
    "    Examples\n",
    "    ----------\n",
    "    For usage examples, please see\n",
    "    https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/fpgrowth/\n",
    "\n",
    "    \"\"\"\n",
    "    valid_input_check(df)\n",
    "\n",
    "    if min_support <= 0.0:\n",
    "        raise ValueError(\n",
    "            \"`min_support` must be a positive \"\n",
    "            \"number within the interval `(0, 1]`. \"\n",
    "            \"Got %s.\" % min_support\n",
    "        )\n",
    "\n",
    "    colname_map = None\n",
    "    if use_colnames:\n",
    "        colname_map = {idx: item for idx, item in enumerate(df.columns)}\n",
    "\n",
    "    tree, _ = setup_fptree(df, min_support)\n",
    "    minsup = math.ceil(min_support * len(df.index))  # min support as count\n",
    "    generator = fpg_step(tree, minsup, colname_map, max_len, verbose)\n",
    "\n",
    "    return generate_itemsets(generator, len(df.index), colname_map)\n",
    "\n",
    "\n",
    "def fpg_step(tree, minsup, colnames, max_len, verbose):\n",
    "    \"\"\"\n",
    "    Performs a recursive step of the fpgrowth algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : FPTree\n",
    "    minsup : int\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    lists of strings\n",
    "        Set of items that has occurred in minsup itemsets.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    items = tree.nodes.keys()\n",
    "    if tree.is_path():\n",
    "        # If the tree is a path, we can combinatorally generate all\n",
    "        # remaining itemsets without generating additional conditional trees\n",
    "        size_remain = len(items) + 1\n",
    "        if max_len:\n",
    "            size_remain = max_len - len(tree.cond_items) + 1\n",
    "        for i in range(1, size_remain):\n",
    "            for itemset in itertools.combinations(items, i):\n",
    "                count += 1\n",
    "                support = min([tree.nodes[i][0].count for i in itemset])\n",
    "                yield support, tree.cond_items + list(itemset)\n",
    "    elif not max_len or max_len > len(tree.cond_items):\n",
    "        for item in items:\n",
    "            count += 1\n",
    "            support = sum([node.count for node in tree.nodes[item]])\n",
    "            # Check if \"Outcome\" is in the itemset\n",
    "            if \"Outcome_0\" in [item] or \"Outcome_1\" in [item]:\n",
    "              yield support, tree.cond_items + [item]\n",
    "\n",
    "    if verbose:\n",
    "        tree.print_status(count, colnames)\n",
    "\n",
    "    # Generate conditional trees to generate frequent itemsets one item larger\n",
    "    if not tree.is_path() and (not max_len or max_len > len(tree.cond_items)):\n",
    "        for item in items:\n",
    "            cond_tree = tree.conditional_tree(item, minsup)\n",
    "            for sup, iset in fpg_step(cond_tree, minsup, colnames, max_len, verbose):\n",
    "                yield sup, iset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kObTO0bXs39",
    "outputId": "dde4e172-cc58-4a3f-ab55-19302119e0b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<ipython-input-16-4da0e870eeb0>:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Call the modified fpgrowth function\n",
    "result = fpgrowth(transactions, min_support=0.01, use_colnames=True)\n",
    "sorted_itemsets = result.sort_values(by='support', ascending=False)\n",
    "\n",
    "# Get the top 100 most frequent itemsets\n",
    "frequent100 = sorted_itemsets.head(100).reset_index()\n",
    "frequent100.drop(columns=['index'],inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
